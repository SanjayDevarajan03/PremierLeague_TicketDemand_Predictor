{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "src_path = os.environ[\"src_path\"]\n",
    "sys.path.append(src_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.components.feature_group_config as config\n",
    "from comet_ml import Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-12 14:47:43,766 INFO: Initializing external client\n",
      "2025-03-12 14:47:43,769 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2025-03-12 14:47:44,748 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1214715\n"
     ]
    },
    {
     "ename": "RestAPIError",
     "evalue": "Metadata operation error: (url: https://c.app.hopsworks.ai/hopsworks-api/api/project/1214715/featurestores/1203325/featuregroups/ticket_demand_feature_group2). Server response: \nHTTP code: 404, HTTP reason: Not Found, body: b'{\"errorCode\":270009,\"usrMsg\":\"feature group name: ticket_demand_feature_group2 feature group version: 3\",\"errorMsg\":\"Featuregroup wasn\\'t found.\"}', error code: 270009, error msg: Featuregroup wasn't found., user msg: feature group name: ticket_demand_feature_group2 feature group version: 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRestAPIError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m feature_store \u001b[38;5;241m=\u001b[39m project\u001b[38;5;241m.\u001b[39mget_feature_store()\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# connect to the feature group\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m feature_group \u001b[38;5;241m=\u001b[39m feature_store\u001b[38;5;241m.\u001b[39mget_feature_group(\n\u001b[1;32m     14\u001b[0m     name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mFEATURE_GROUP_METADATA\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m     15\u001b[0m     version \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mFEATURE_GROUP_METADATA\u001b[38;5;241m.\u001b[39mversion\n\u001b[1;32m     16\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/hsfs/feature_store.py:170\u001b[0m, in \u001b[0;36mFeatureStore.get_feature_group\u001b[0;34m(self, name, version)\u001b[0m\n\u001b[1;32m    162\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    163\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo version provided for getting feature group `\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m`, defaulting to `\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    164\u001b[0m             name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mDEFAULT_VERSION\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    167\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    168\u001b[0m     )\n\u001b[1;32m    169\u001b[0m     version \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mDEFAULT_VERSION\n\u001b[0;32m--> 170\u001b[0m feature_group_object \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_feature_group_api\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid, name, version)\n\u001b[1;32m    171\u001b[0m feature_group_object\u001b[38;5;241m.\u001b[39mfeature_store \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m feature_group_object\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/hsfs/core/feature_group_api.py:110\u001b[0m, in \u001b[0;36mFeatureGroupApi.get\u001b[0;34m(self, feature_store_id, name, version)\u001b[0m\n\u001b[1;32m    107\u001b[0m fg_objs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    108\u001b[0m \u001b[38;5;66;03m# In principle unique names are enforced across fg type and this should therefore\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;66;03m# return only list of the same type. But it cost nothing to check in case this gets forgotten.\u001b[39;00m\n\u001b[0;32m--> 110\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fg_json \u001b[38;5;129;01min\u001b[39;00m _client\u001b[38;5;241m.\u001b[39m_send_request(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGET\u001b[39m\u001b[38;5;124m\"\u001b[39m, path_params, query_params):\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    112\u001b[0m         fg_json[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m FeatureGroupApi\u001b[38;5;241m.\u001b[39mBACKEND_FG_STREAM\n\u001b[1;32m    113\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m fg_json[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m FeatureGroupApi\u001b[38;5;241m.\u001b[39mBACKEND_FG_BATCH\n\u001b[1;32m    114\u001b[0m     ):\n\u001b[1;32m    115\u001b[0m         fg_objs\u001b[38;5;241m.\u001b[39mappend(fg_mod\u001b[38;5;241m.\u001b[39mFeatureGroup\u001b[38;5;241m.\u001b[39mfrom_response_json(fg_json))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/hopsworks_common/decorators.py:45\u001b[0m, in \u001b[0;36mconnected.<locals>.if_connected\u001b[0;34m(inst, *args, **kwargs)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m inst\u001b[38;5;241m.\u001b[39m_connected:\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NoHopsworksConnectionError\n\u001b[0;32m---> 45\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(inst, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/hopsworks_common/client/base.py:186\u001b[0m, in \u001b[0;36mClient._send_request\u001b[0;34m(self, method, path_params, query_params, headers, data, stream, files, with_base_path_params)\u001b[0m\n\u001b[1;32m    181\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry_token_expired(\n\u001b[1;32m    182\u001b[0m         request, stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mTOKEN_EXPIRED_RETRY_INTERVAL, \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    183\u001b[0m     )\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m--> 186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mRestAPIError(url, response)\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[0;31mRestAPIError\u001b[0m: Metadata operation error: (url: https://c.app.hopsworks.ai/hopsworks-api/api/project/1214715/featurestores/1203325/featuregroups/ticket_demand_feature_group2). Server response: \nHTTP code: 404, HTTP reason: Not Found, body: b'{\"errorCode\":270009,\"usrMsg\":\"feature group name: ticket_demand_feature_group2 feature group version: 3\",\"errorMsg\":\"Featuregroup wasn\\'t found.\"}', error code: 270009, error msg: Featuregroup wasn't found., user msg: feature group name: ticket_demand_feature_group2 feature group version: 3"
     ]
    }
   ],
   "source": [
    "import hopsworks\n",
    "\n",
    "# connect to the project\n",
    "project = hopsworks.login(\n",
    "    project=config.HOPSWORKS_PROJECT_NAME,\n",
    "    api_key_value= config.HOPSWORKS_API_KEY\n",
    ")\n",
    "\n",
    "# connect to the feature store\n",
    "feature_store = project.get_feature_store()\n",
    "\n",
    "# connect to the feature group\n",
    "feature_group = feature_store.get_feature_group(\n",
    "    name=config.FEATURE_GROUP_METADATA.name,\n",
    "    version = config.FEATURE_GROUP_METADATA.version\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature view already existed. Skip creation.\n"
     ]
    },
    {
     "ename": "RestAPIError",
     "evalue": "Metadata operation error: (url: https://c.app.hopsworks.ai/hopsworks-api/api/project/1214715/featurestores/1203325/featureview/ticket_demand_feature_view2/version/3). Server response: \nHTTP code: 404, HTTP reason: Not Found, body: b'{\"errorCode\":270181,\"usrMsg\":\"There exists no feature view with the name ticket_demand_feature_view2 and version 3.\",\"errorMsg\":\"Feature view wasn\\'t found.\"}', error code: 270181, error msg: Feature view wasn't found., user msg: There exists no feature view with the name ticket_demand_feature_view2 and version 3.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRestAPIError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFeature view already existed. Skip creation.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# get feature view\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m feature_view \u001b[38;5;241m=\u001b[39m feature_store\u001b[38;5;241m.\u001b[39mget_feature_view(\n\u001b[1;32m     14\u001b[0m     name \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mFEATURE_VIEW_METADATA\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m     15\u001b[0m     version \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mFEATURE_VIEW_METADATA\u001b[38;5;241m.\u001b[39mversion\n\u001b[1;32m     16\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/hopsworks_common/usage.py:246\u001b[0m, in \u001b[0;36mmethod_logger.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    245\u001b[0m     exception \u001b[38;5;241m=\u001b[39m e\n\u001b[0;32m--> 246\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/hopsworks_common/usage.py:242\u001b[0m, in \u001b[0;36mmethod_logger.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    239\u001b[0m exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;66;03m# Call the original method\u001b[39;00m\n\u001b[0;32m--> 242\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/hsfs/feature_store.py:1778\u001b[0m, in \u001b[0;36mFeatureStore.get_feature_view\u001b[0;34m(self, name, version)\u001b[0m\n\u001b[1;32m   1770\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1771\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo version provided for getting feature view `\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m`, defaulting to `\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1772\u001b[0m             name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mDEFAULT_VERSION\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1775\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1776\u001b[0m     )\n\u001b[1;32m   1777\u001b[0m     version \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mDEFAULT_VERSION\n\u001b[0;32m-> 1778\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_feature_view_engine\u001b[38;5;241m.\u001b[39mget(name, version)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/hsfs/core/feature_view_engine.py:184\u001b[0m, in \u001b[0;36mFeatureViewEngine.get\u001b[0;34m(self, name, version)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;124;03mGet a feature view form the backend using name or using name and version.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;124;03m    `ValueError`: If the feature group associated with the feature view cannot be found.\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m version:\n\u001b[0;32m--> 184\u001b[0m     fv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_feature_view_api\u001b[38;5;241m.\u001b[39mget_by_name_version(name, version)\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    186\u001b[0m     fv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_feature_view_api\u001b[38;5;241m.\u001b[39mget_by_name(name)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/hsfs/core/feature_view_api.py:156\u001b[0m, in \u001b[0;36mFeatureViewApi.get_by_name_version\u001b[0;34m(self, name, version)\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    151\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot get back the feature view because the query defined is no longer valid.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    152\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Some feature groups used in the query may have been deleted. You can clean up this feature view on the UI\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    153\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m or `FeatureView.clean`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    154\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 156\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/hsfs/core/feature_view_api.py:142\u001b[0m, in \u001b[0;36mFeatureViewApi.get_by_name_version\u001b[0;34m(self, name, version)\u001b[0m\n\u001b[1;32m    139\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_base_path \u001b[38;5;241m+\u001b[39m [name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_VERSION, version]\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m feature_view\u001b[38;5;241m.\u001b[39mFeatureView\u001b[38;5;241m.\u001b[39mfrom_response_json(\n\u001b[0;32m--> 142\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39m_send_request(\n\u001b[1;32m    143\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_GET,\n\u001b[1;32m    144\u001b[0m             path,\n\u001b[1;32m    145\u001b[0m             {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpand\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransformationfunctions\u001b[39m\u001b[38;5;124m\"\u001b[39m]},\n\u001b[1;32m    146\u001b[0m         )\n\u001b[1;32m    147\u001b[0m     )\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RestAPIError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mjson()\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merrorCode\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m270009\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/hopsworks_common/decorators.py:45\u001b[0m, in \u001b[0;36mconnected.<locals>.if_connected\u001b[0;34m(inst, *args, **kwargs)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m inst\u001b[38;5;241m.\u001b[39m_connected:\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NoHopsworksConnectionError\n\u001b[0;32m---> 45\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(inst, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/hopsworks_common/client/base.py:186\u001b[0m, in \u001b[0;36mClient._send_request\u001b[0;34m(self, method, path_params, query_params, headers, data, stream, files, with_base_path_params)\u001b[0m\n\u001b[1;32m    181\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry_token_expired(\n\u001b[1;32m    182\u001b[0m         request, stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mTOKEN_EXPIRED_RETRY_INTERVAL, \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    183\u001b[0m     )\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m--> 186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mRestAPIError(url, response)\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[0;31mRestAPIError\u001b[0m: Metadata operation error: (url: https://c.app.hopsworks.ai/hopsworks-api/api/project/1214715/featurestores/1203325/featureview/ticket_demand_feature_view2/version/3). Server response: \nHTTP code: 404, HTTP reason: Not Found, body: b'{\"errorCode\":270181,\"usrMsg\":\"There exists no feature view with the name ticket_demand_feature_view2 and version 3.\",\"errorMsg\":\"Feature view wasn\\'t found.\"}', error code: 270181, error msg: Feature view wasn't found., user msg: There exists no feature view with the name ticket_demand_feature_view2 and version 3."
     ]
    }
   ],
   "source": [
    "# create feature view (if it doesn't exist yet)\n",
    "# This feature view only uses on feature group, so the query is trivial\n",
    "try:\n",
    "    # create feature view if it doesn't exist yet.\n",
    "    feature_store.create_feature_view(\n",
    "        name = config.FEATURE_VIEW_METADATA.name,\n",
    "        version = config.FEATURE_VIEW_METADATA.version\n",
    "    )\n",
    "except:\n",
    "    print('Feature view already existed. Skip creation.')\n",
    "\n",
    "# get feature view\n",
    "feature_view = feature_store.get_feature_view(\n",
    "    name = config.FEATURE_VIEW_METADATA.name,\n",
    "    version = config.FEATURE_VIEW_METADATA.version\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feature_view' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data, _ \u001b[38;5;241m=\u001b[39m feature_view\u001b[38;5;241m.\u001b[39mtraining_data(\n\u001b[1;32m      2\u001b[0m     description \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTime-series hourly ticket demand values.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'feature_view' is not defined"
     ]
    }
   ],
   "source": [
    "data, _ = feature_view.training_data(\n",
    "    description = \"Time-series hourly ticket demand values.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# drop `date` column\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m data\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseconds\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# sort by `pickup_location_id` and `pickup_hour` \u001b[39;00m\n\u001b[1;32m      5\u001b[0m data\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msub_region_code\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m], inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "# drop `date` column\n",
    "data.drop('seconds', axis=1, inplace=True)\n",
    "\n",
    "# sort by `pickup_location_id` and `pickup_hour` \n",
    "data.sort_values(by=['sub_region_code', 'date'], inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# transform the batch of data to features and target\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomponents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_info\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transform_ts_data_into_features_and_target\n\u001b[1;32m      4\u001b[0m features, targets \u001b[38;5;241m=\u001b[39m transform_ts_data_into_features_and_target(\n\u001b[0;32m----> 5\u001b[0m     data,\n\u001b[1;32m      6\u001b[0m     input_seq_len\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m24\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m28\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m      7\u001b[0m     step_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m23\u001b[39m\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m     10\u001b[0m features_and_target \u001b[38;5;241m=\u001b[39m features\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m     11\u001b[0m features_and_target[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget_demand_value_next_hour\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m targets\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "# transform the batch of data to features and target\n",
    "from src.components.data_info import transform_ts_data_into_features_and_target\n",
    "\n",
    "features, targets = transform_ts_data_into_features_and_target(\n",
    "    data,\n",
    "    input_seq_len=24*28*1,\n",
    "    step_size=23\n",
    ")\n",
    "\n",
    "features_and_target = features.copy()\n",
    "features_and_target['target_demand_value_next_hour'] = targets\n",
    "\n",
    "print(f'{features_and_target.shape=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_and_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_and_target.date.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_and_target.date.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data\n",
    "from datetime import date, timedelta\n",
    "from pytz import timezone\n",
    "import pandas as pd\n",
    "from src.components.data_info import train_test_split\n",
    "\n",
    "cutoff_date = pd.to_datetime(date.today() - timedelta(days=60), utc=True)\n",
    "\n",
    "print(f'{cutoff_date=}')\n",
    "\n",
    "X_train, y_train, X_test, y_test = train_test_split(\n",
    "    features_and_target,\n",
    "    cutoff_date,\n",
    "    target_column_name = 'target_demand_values_next_hour'\n",
    ")\n",
    "\n",
    "print(f'{X_train.shape=}')\n",
    "print(f'{y_train.shape=}')\n",
    "print(f'{X_test.shape=}')\n",
    "print(f'{y_test.shape=}')\n",
    "print(f\"Training data range: {X_train['date'].min()} to {X_train['date'].max()}\")\n",
    "print(f\"Testing data range: {X_test['date'].min()} to {X_test['date'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr = X_train.drop(['date'], axis=1)\n",
    "x_ts = X_test.drop(['date'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline model Linear Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Create and train the linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(x_tr, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_ts)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "def evaluate_model(y_test, y_pred):\n",
    "    test_mae = mean_absolute_error(y_test, y_pred)\n",
    "    test_mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "    return f\"MAE is {test_mae:.4f} and MAPE is {test_mape:.4f}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, TimeSeriesSplit\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import optuna\n",
    "\n",
    "from src.components.model_info import get_pipeline\n",
    "\n",
    "def objective(trial: optuna.trial.Trial) -> float:\n",
    "    \"\"\"\n",
    "    Given a set of hyper-parameters, it trains a model and computes an average\n",
    "    validation error based on a TimeSeriesSplit\n",
    "    \"\"\"\n",
    "    # picking hyper-parameters\n",
    "    hyperparams = {\n",
    "        \"metrics\": \"mae\",\n",
    "        \"verbose\": -1,\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\",2,256),\n",
    "        \"feature_fraction\":trial.suggest_float(\"feature_fraction\", 0.2, 1.0),\n",
    "        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.2, 1.0),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 3, 100)\n",
    "    }\n",
    "\n",
    "    tss = KFold(n_splits=5)\n",
    "    scores = []\n",
    "\n",
    "    for train_index, val_index in tss.split(X_train):\n",
    "        #split data for training and validation\n",
    "        X_train_, X_val_ = X_train.iloc[train_index, :], X_train.iloc[val_index, :]\n",
    "        y_train_, y_val_ = y_train.iloc[train_index, :], y_train.iloc[val_index]\n",
    "\n",
    "        # train the model\n",
    "        pipeline = get_pipeline(**hyperparams)\n",
    "        pipeline.fit(X_train, y_train)\n",
    "\n",
    "        # evaluate the model\n",
    "        y_pred = pipeline.predict(X_val_)\n",
    "        mae = mean_absolute_error(y_val_, y_pred)\n",
    "\n",
    "        scores.append(mae)\n",
    "\n",
    "    return np.array(scores).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trails=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = study.best_trial.params\n",
    "print(f'{best_params=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = get_pipeline(**best_params)\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.components.model_info import evaluate_model\n",
    "\n",
    "predictions = pipeline.predict(X_test)\n",
    "test_mae = mean_absolute_error(y_test, predictions)\n",
    "print(f'{test_mae:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the result\n",
    "from src.plot import plot_one_sample\n",
    "\n",
    "plot_one_sample(\n",
    "    example_id=1,\n",
    "    features=X_test,\n",
    "    targets=y_test,\n",
    "    predictions = pd.Series(predictions)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from src.paths import MODELS_DIR\n",
    "\n",
    "joblib.dump(pipeline, MODELS_DIR/'LGB_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in order to save to model for model registry we have to create schema first\n",
    "from hsml.schema import Schema\n",
    "from hsml.model_schema import ModelSchema\n",
    "\n",
    "input_schema = Schema(X_train)\n",
    "output_schema = Schema(y_train)\n",
    "model_schema = ModelSchema(input_schema=input_schema, output_schema=output_schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_registry = project.get_model_registry()\n",
    "model = model_registry.sklearn.create_model(\n",
    "    name=\"ticket_demand_predictor_next_hour\",\n",
    "    metrics = {\"test_mae\": test_mae},\n",
    "    description = \"LightGBM regressor with a bit of hyper-parameter tuning\",\n",
    "    input_example = X_train.sample(),\n",
    "    model_schema = model_schema\n",
    ")\n",
    "\n",
    "model.save(str(MODELS_DIR/'LGB_model.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
